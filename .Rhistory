for(j in 1:q1){
B.estimate[cand[j],i] <- coef(m1)[j+2]
}
}
# Step 1c
Importance <- abs(rowSums(B.estimate)/B)
# Step 2a
S2 <- matrix(sample(1:n,n*B,replace=T),nrow=n,ncol=B)
# Step 2b
# Normalize importance weights
N.Importance <- Importance/sum(Importance)
B.estimate2 <- matrix(rep(0,B*ncol(X)),nrow=ncol(X),ncol=B)
int.val <- rep(NA,B)
for(i in 1:B){
# select q candidate variables based on number of predictors in X (ncol(X))
cand2 <- sort(sample(1:ncol(X),q2,replace=F,prob=N.Importance))
# Make X matrix from Bootstrap indices from step1 (S1 matrix is nxB)
# select only the candidate variables as well (cv)
X2 <- X[S2[,i],cand]
# Make Y vector from Bootsrap indices from step1
Y2 <- Y[S2[,i]]
if(is.null(lambda)){
# Use cross-validation to find lambda
cv.lasso2 <- glmnet::cv.glmnet(X2, Y2, alpha=1, nfolds=5, family=fam,intercept=FALSE)
l2 <- cv.lasso2$lambda.min
}
else{
l2 <- lambda
}
# Create model based on lambda, X2, Y2
# glmnet mean-centers data by default: https://statisticaloddsandends.wordpress.com/2018/11/15/a-deep-dive-into-glmnet-standardize/
# (standardize=TRUE)
# change intercept parameter to FALSE
m2 <- glmnet::glmnet(X2,Y2,family=fam,alpha=1,lambda=l2,intercept=FALSE)
# assign coefficients to their correct spot in matrix
# Logic = cand variable is sorted, so coef(m) will match that ordering (+1 due to interept)
for(j in 1:q2){
B.estimate2[cand[j],i] <- coef(m2)[j+2]
}
}
# Step 2c
Final.Betas <- rowSums(B.estimate2)/B
return(list(B.coefs=Final.Betas))
}
extended.randomlasso(X2,Y2,lambda=-1)
extended.randomlasso <- function(X,Y,lambda=NULL,B=200,q1=length(Y),q2=length(Y),ytype="continuous"){
if(ytype != "continuous" & ytype != "binary"){
stop("ytype must be 'continuous' or 'binary'")
} else if(lambda <= 0){
stop("lambda must be positive")
} else if(q1 > length(Y) | q2 > length(Y)){
stop("q values must both be less than or equal to length(Y)")
}
# Step 1a
# make matrix of indices for Bootstrap samples
# B = number of Bootstraps
# n = number of observations
n <- length(Y)
if(ytype=="continuous"){
fam <- "gaussian"
} else if(ytype=="binary"){
fam <- "binomial"
}
S1 <- matrix(sample(1:n,n*B,replace=T),nrow=n,ncol=B)
# Step 1b
B.estimate <- matrix(rep(0,B*ncol(X)),nrow=ncol(X),ncol=B)
B.estimate.s <- matrix(rep(0,B*ncol(X)),nrow=ncol(X),ncol=B)
for(i in 1:B){
# select q candidate variables based on number of predictors in X (ncol(X))
cand <- sort(sample(1:ncol(X),q1,replace=F))
# Make X matrix from Bootstrap indices from step1 (S1 matrix is nxB)
# select only the candidate variables as well (cand)
X1 <- X[S1[,i],cand]
# Make Y vector from Bootstrap indices from step1
Y1 <- Y[S1[,i]]
if(is.null(lambda)){
# Use cross-validation to find lambda
cv.lasso <- glmnet::cv.glmnet(X1, Y1, alpha=1, nfolds=5, family=fam,intercept=FALSE)
l <- cv.lasso$lambda.min
}
else{
l <- lambda
}
# Create model based on lambda, X1, Y1
# glmnet mean-centers data by default: https://statisticaloddsandends.wordpress.com/2018/11/15/a-deep-dive-into-glmnet-standardize/
# (standardize=TRUE)
# change intercept parameter to FALSE
m1 <- glmnet::glmnet(X1,Y1,family=fam,alpha=1,lambda=l,intercept=FALSE)
# assign coefficients to their correct spot in matrix
# Logic = cand variable is sorted, so coef(m) will match that ordering (+2 due to intercept row and unknown second row)
for(j in 1:q1){
B.estimate[cand[j],i] <- coef(m1)[j+2]
}
}
# Step 1c
Importance <- abs(rowSums(B.estimate)/B)
# Step 2a
S2 <- matrix(sample(1:n,n*B,replace=T),nrow=n,ncol=B)
# Step 2b
# Normalize importance weights
N.Importance <- Importance/sum(Importance)
B.estimate2 <- matrix(rep(0,B*ncol(X)),nrow=ncol(X),ncol=B)
int.val <- rep(NA,B)
for(i in 1:B){
# select q candidate variables based on number of predictors in X (ncol(X))
cand2 <- sort(sample(1:ncol(X),q2,replace=F,prob=N.Importance))
# Make X matrix from Bootstrap indices from step1 (S1 matrix is nxB)
# select only the candidate variables as well (cv)
X2 <- X[S2[,i],cand]
# Make Y vector from Bootsrap indices from step1
Y2 <- Y[S2[,i]]
if(is.null(lambda)){
# Use cross-validation to find lambda
cv.lasso2 <- glmnet::cv.glmnet(X2, Y2, alpha=1, nfolds=5, family=fam,intercept=FALSE)
l2 <- cv.lasso2$lambda.min
}
else{
l2 <- lambda
}
# Create model based on lambda, X2, Y2
# glmnet mean-centers data by default: https://statisticaloddsandends.wordpress.com/2018/11/15/a-deep-dive-into-glmnet-standardize/
# (standardize=TRUE)
# change intercept parameter to FALSE
m2 <- glmnet::glmnet(X2,Y2,family=fam,alpha=1,lambda=l2,intercept=FALSE)
# assign coefficients to their correct spot in matrix
# Logic = cand variable is sorted, so coef(m) will match that ordering (+1 due to interept)
for(j in 1:q2){
B.estimate2[cand[j],i] <- coef(m2)[j+2]
}
}
# Step 2c
Final.Betas <- rowSums(B.estimate2)/B
return(list(B.coefs=Final.Betas))
}
extended.randomlasso(X2,Y2,lambda=-1)
extended.randomlasso(X2,Y2,q1=80)
extended.randomlasso <- function(X,Y,lambda=NULL,B=200,q1=length(Y),q2=length(Y),ytype="continuous"){
if(ytype != "continuous" & ytype != "binary"){
stop("ytype must be 'continuous' or 'binary'")
} else if(is.numeric(lambda) & lambda <= 0){
stop("lambda must be positive")
} else if(q1 > length(Y) | q2 > length(Y)){
stop("q values must both be less than or equal to length(Y)")
}
# Step 1a
# make matrix of indices for Bootstrap samples
# B = number of Bootstraps
# n = number of observations
n <- length(Y)
if(ytype=="continuous"){
fam <- "gaussian"
} else if(ytype=="binary"){
fam <- "binomial"
}
S1 <- matrix(sample(1:n,n*B,replace=T),nrow=n,ncol=B)
# Step 1b
B.estimate <- matrix(rep(0,B*ncol(X)),nrow=ncol(X),ncol=B)
B.estimate.s <- matrix(rep(0,B*ncol(X)),nrow=ncol(X),ncol=B)
for(i in 1:B){
# select q candidate variables based on number of predictors in X (ncol(X))
cand <- sort(sample(1:ncol(X),q1,replace=F))
# Make X matrix from Bootstrap indices from step1 (S1 matrix is nxB)
# select only the candidate variables as well (cand)
X1 <- X[S1[,i],cand]
# Make Y vector from Bootstrap indices from step1
Y1 <- Y[S1[,i]]
if(is.null(lambda)){
# Use cross-validation to find lambda
cv.lasso <- glmnet::cv.glmnet(X1, Y1, alpha=1, nfolds=5, family=fam,intercept=FALSE)
l <- cv.lasso$lambda.min
}
else{
l <- lambda
}
# Create model based on lambda, X1, Y1
# glmnet mean-centers data by default: https://statisticaloddsandends.wordpress.com/2018/11/15/a-deep-dive-into-glmnet-standardize/
# (standardize=TRUE)
# change intercept parameter to FALSE
m1 <- glmnet::glmnet(X1,Y1,family=fam,alpha=1,lambda=l,intercept=FALSE)
# assign coefficients to their correct spot in matrix
# Logic = cand variable is sorted, so coef(m) will match that ordering (+2 due to intercept row and unknown second row)
for(j in 1:q1){
B.estimate[cand[j],i] <- coef(m1)[j+2]
}
}
# Step 1c
Importance <- abs(rowSums(B.estimate)/B)
# Step 2a
S2 <- matrix(sample(1:n,n*B,replace=T),nrow=n,ncol=B)
# Step 2b
# Normalize importance weights
N.Importance <- Importance/sum(Importance)
B.estimate2 <- matrix(rep(0,B*ncol(X)),nrow=ncol(X),ncol=B)
int.val <- rep(NA,B)
for(i in 1:B){
# select q candidate variables based on number of predictors in X (ncol(X))
cand2 <- sort(sample(1:ncol(X),q2,replace=F,prob=N.Importance))
# Make X matrix from Bootstrap indices from step1 (S1 matrix is nxB)
# select only the candidate variables as well (cv)
X2 <- X[S2[,i],cand]
# Make Y vector from Bootsrap indices from step1
Y2 <- Y[S2[,i]]
if(is.null(lambda)){
# Use cross-validation to find lambda
cv.lasso2 <- glmnet::cv.glmnet(X2, Y2, alpha=1, nfolds=5, family=fam,intercept=FALSE)
l2 <- cv.lasso2$lambda.min
}
else{
l2 <- lambda
}
# Create model based on lambda, X2, Y2
# glmnet mean-centers data by default: https://statisticaloddsandends.wordpress.com/2018/11/15/a-deep-dive-into-glmnet-standardize/
# (standardize=TRUE)
# change intercept parameter to FALSE
m2 <- glmnet::glmnet(X2,Y2,family=fam,alpha=1,lambda=l2,intercept=FALSE)
# assign coefficients to their correct spot in matrix
# Logic = cand variable is sorted, so coef(m) will match that ordering (+1 due to interept)
for(j in 1:q2){
B.estimate2[cand[j],i] <- coef(m2)[j+2]
}
}
# Step 2c
Final.Betas <- rowSums(B.estimate2)/B
return(list(B.coefs=Final.Betas))
}
extended.randomlasso(X2,Y2,q1=80)
extended.randomlasso <- function(X,Y,lambda=NULL,B=200,q1=length(Y),q2=length(Y),ytype="continuous"){
if(ytype != "continuous" & ytype != "binary"){
stop("ytype must be 'continuous' or 'binary'")
} else if(is.numeric(lambda)){
if(lambda <= 0){
stop("lambda must be greater than 0")
}
}
} else if(q1 > length(Y) | q2 > length(Y)){
stop("q values must both be less than or equal to length(Y)")
}
extended.randomlasso <- function(X,Y,lambda=NULL,B=200,q1=length(Y),q2=length(Y),ytype="continuous"){
if(ytype != "continuous" & ytype != "binary"){
stop("ytype must be 'continuous' or 'binary'")
} else if(is.numeric(lambda)){
if(lambda <= 0){
stop("lambda must be greater than 0")
}
} else if(q1 > length(Y) | q2 > length(Y)){
stop("q values must both be less than or equal to length(Y)")
}
# Step 1a
# make matrix of indices for Bootstrap samples
# B = number of Bootstraps
# n = number of observations
n <- length(Y)
if(ytype=="continuous"){
fam <- "gaussian"
} else if(ytype=="binary"){
fam <- "binomial"
}
S1 <- matrix(sample(1:n,n*B,replace=T),nrow=n,ncol=B)
# Step 1b
B.estimate <- matrix(rep(0,B*ncol(X)),nrow=ncol(X),ncol=B)
B.estimate.s <- matrix(rep(0,B*ncol(X)),nrow=ncol(X),ncol=B)
for(i in 1:B){
# select q candidate variables based on number of predictors in X (ncol(X))
cand <- sort(sample(1:ncol(X),q1,replace=F))
# Make X matrix from Bootstrap indices from step1 (S1 matrix is nxB)
# select only the candidate variables as well (cand)
X1 <- X[S1[,i],cand]
# Make Y vector from Bootstrap indices from step1
Y1 <- Y[S1[,i]]
if(is.null(lambda)){
# Use cross-validation to find lambda
cv.lasso <- glmnet::cv.glmnet(X1, Y1, alpha=1, nfolds=5, family=fam,intercept=FALSE)
l <- cv.lasso$lambda.min
}
else{
l <- lambda
}
# Create model based on lambda, X1, Y1
# glmnet mean-centers data by default: https://statisticaloddsandends.wordpress.com/2018/11/15/a-deep-dive-into-glmnet-standardize/
# (standardize=TRUE)
# change intercept parameter to FALSE
m1 <- glmnet::glmnet(X1,Y1,family=fam,alpha=1,lambda=l,intercept=FALSE)
# assign coefficients to their correct spot in matrix
# Logic = cand variable is sorted, so coef(m) will match that ordering (+2 due to intercept row and unknown second row)
for(j in 1:q1){
B.estimate[cand[j],i] <- coef(m1)[j+2]
}
}
# Step 1c
Importance <- abs(rowSums(B.estimate)/B)
# Step 2a
S2 <- matrix(sample(1:n,n*B,replace=T),nrow=n,ncol=B)
# Step 2b
# Normalize importance weights
N.Importance <- Importance/sum(Importance)
B.estimate2 <- matrix(rep(0,B*ncol(X)),nrow=ncol(X),ncol=B)
int.val <- rep(NA,B)
for(i in 1:B){
# select q candidate variables based on number of predictors in X (ncol(X))
cand2 <- sort(sample(1:ncol(X),q2,replace=F,prob=N.Importance))
# Make X matrix from Bootstrap indices from step1 (S1 matrix is nxB)
# select only the candidate variables as well (cv)
X2 <- X[S2[,i],cand]
# Make Y vector from Bootsrap indices from step1
Y2 <- Y[S2[,i]]
if(is.null(lambda)){
# Use cross-validation to find lambda
cv.lasso2 <- glmnet::cv.glmnet(X2, Y2, alpha=1, nfolds=5, family=fam,intercept=FALSE)
l2 <- cv.lasso2$lambda.min
}
else{
l2 <- lambda
}
# Create model based on lambda, X2, Y2
# glmnet mean-centers data by default: https://statisticaloddsandends.wordpress.com/2018/11/15/a-deep-dive-into-glmnet-standardize/
# (standardize=TRUE)
# change intercept parameter to FALSE
m2 <- glmnet::glmnet(X2,Y2,family=fam,alpha=1,lambda=l2,intercept=FALSE)
# assign coefficients to their correct spot in matrix
# Logic = cand variable is sorted, so coef(m) will match that ordering (+1 due to interept)
for(j in 1:q2){
B.estimate2[cand[j],i] <- coef(m2)[j+2]
}
}
# Step 2c
Final.Betas <- rowSums(B.estimate2)/B
return(list(B.coefs=Final.Betas))
}
extended.randomlasso(X2,Y2,q1=80)
extended.lasso <- function(X,Y,lambda=NULL,ytype="continuous"){
if(ytype != "continuous" & ytype != "binary"){
stop("ytype must be 'continuous' or 'binary'")
} else if(is.numeric(lambda)){
if(lambda <= 0){
stop("lambda must be greater than 0")
}
}
data <- as.data.frame(cbind(X,y=Y))
if(ytype=="continuous"){
fam <- "gaussian"
} else if(ytype=="binary"){
fam <- "binomial"
}
if(is.null(lambda)){
cv.lasso <- glmnet::cv.glmnet(data.matrix(X), Y, alpha=1, nfolds=5, family=fam)
l = cv.lasso$lambda.min
}
else{
l = lambda
}
fit <- glmnet::glmnet(X,Y,family=fam,alpha=1,lambda=l)
return(fit)
}
extended.lasso(X2,Y2,lambda=-4)
extended.lasso(X2,Y2,q1=80)
extended.lasso(X2,Y2,ytype=5)
devtools::build()
devtools::install()
devtools::build()
devtools::install()
print("hi")
dd <- create.regr.data(72,3751)$Data
X2 <- dd[,1:(ncol(dd)-1)]
Y2 <- dd[,c(ncol(dd))]
fit <- extended.randomlasso(X2,Y2,lambda=100,ytype="continuous")
dd <- create.regr.data(72,3751)$Data
X2 <- dd[,1:(ncol(dd)-1)]
Y2 <- dd[,c(ncol(dd))]
fit <- extended.lasso(X2,Y2,lambda=100,ytype="continuous")
nonzero.c <- length(coef(fit)[coef(fit) != 0])
paste("There are",nonzero.c-1,"zonzero coefficients")
devtools::build()
devtools::build()
devtools::install()
devtools::install()
devtools::document()
devtools::build()
devtools::install()
X <- dat[,2:ncol(dat)]
Y <- dat[,1]
fit <- extended.lasso(X,Y,ytype="binary")
nonzero.c <- length(coef(fit)[coef(fit) != 0])
paste("There are",nonzero.c-1,"zonzero coefficients")
dd <- create.regr.data(72,3751)$Data
X2 <- dd[,1:(ncol(dd)-1)]
Y2 <- dd[,c(ncol(dd))]
fit <- extended.randomlasso(X2,Y2,q1=200,q2=50,ytype="continuous")
dd <- create.regr.data(72,3751)$Data
X2 <- dd[,1:(ncol(dd)-1)]
Y2 <- dd[,c(ncol(dd))]
fit <- extended.randomlasso(X2,Y2,q1=65,q2=50,ytype="continuous")
devtools::document()
devtools::build()
devtools::install()
dd <- create.regr.data(72,3751)$Data
X2 <- dd[,1:(ncol(dd)-1)]
Y2 <- dd[,c(ncol(dd))]
fit <- extended.randomlasso(X2,Y2,q1=65,q2=50,ytype="continuous")
dd <- create.regr.data(72,3751)$Data
X2 <- dd[,1:(ncol(dd)-1)]
Y2 <- dd[,c(ncol(dd))]
fit <- extended.randomlasso(X2,Y2,q1=65,q2=50,ytype="continuous")
detach("package:extendedglmnetGroup7", unload = TRUE)
library(extendedglmnetGroup7)
dd <- create.regr.data(72,3751)$Data
X2 <- dd[,1:(ncol(dd)-1)]
Y2 <- dd[,c(ncol(dd))]
fit <- extended.randomlasso(X2,Y2,q1=65,q2=50,ytype="continuous")
nonzero.c <- length(coef(fit)[coef(fit) != 0])
paste("There are",nonzero.c-1,"nonzero coefficients")
X <- dat[,2:ncol(dat)]
Y <- dat[,1]
fit <- extended.lasso(X,Y,ytype="binary")
nonzero.c <- length(coef(fit)[coef(fit) != 0])
paste("There are",nonzero.c-1,"nonzero coefficients")
X <- dat[,2:ncol(dat)]
Y <- dat[,1]
fit <- extended.randomlasso(X,Y,ytype="binary")
nonzero.c <- length(coef(fit)[coef(fit) != 0])
paste("There are",nonzero.c-1,"nonzero coefficients")
max(0,-1)
dd <- create.regr.data(72,3751)$Data
X2 <- dd[,1:(ncol(dd)-1)]
Y2 <- dd[,c(ncol(dd))]
fit <- extended.randomlasso(X2,Y2,q1=5,q2=10,ytype="continuous")
nonzero.c <- length(coef(fit)[coef(fit) != 0])
paste("There are",max(nonzero.c-1,0),"nonzero coefficients")
dd <- create.regr.data(72,3751)$Data
X2 <- dd[,1:(ncol(dd)-1)]
Y2 <- dd[,c(ncol(dd))]
fit <- extended.randomlasso(X2,Y2,q1=10,q2=5,ytype="continuous")
nonzero.c <- length(coef(fit)[coef(fit) != 0])
paste("There are",max(nonzero.c-1,0),"nonzero coefficients")
dd <- create.regr.data(72,3751)$Data
X2 <- dd[,1:(ncol(dd)-1)]
Y2 <- dd[,c(ncol(dd))]
fit <- extended.randomlasso(X2,Y2,q1=10,q2=5,ytype="continuous")
#nonzero.c <- length(coef(fit)[coef(fit) != 0])
fit
#paste("There are",max(nonzero.c-1,0),"nonzero coefficients")
fit$B.coefs
fit$B.coefs[fit$B.coefs != 0]
dd <- create.regr.data(72,3751)$Data
X2 <- dd[,1:(ncol(dd)-1)]
Y2 <- dd[,c(ncol(dd))]
fit <- extended.randomlasso(X2,Y2,q1=10,q2=5,ytype="continuous")
nonzero.c <- length(fit$B.coefs[fit$B.coefs != 0])
paste("There are",nonzero.c-1,"nonzero coefficients")
X <- dat[,2:ncol(dat)]
Y <- dat[,1]
fit <- extended.randomlasso(X,Y,ytype="binary")
nonzero.c <- length(fit$B.coefs[fit$B.coefs != 0])
paste("There are",nonzero.c,"nonzero coefficients")
devtools::document()
devtools::build()
devtools::install()
create.regr.data <- function(n,p,ytype="continuous",include.categorical=FALSE){
if(ytype != "continuous" & ytype != "binary"){
stop("ytype must be 'continuous' or 'binary'")
}
if(include.categorical==TRUE){
p.continuous <- round(p*runif(1))
}
else{
p.continuous <- p
}
p.binary <- p-p.continuous
betas <- runif(p+1,-10,10)
# set random means and random sampling probabilities for binomial
random.params <- c(runif(p.continuous,-10,10),runif(p.binary))
X <- matrix(rep(NA,n*p),nrow=n,ncol=p)
for(i in 1:p){
if(i <= p.continuous){
X[,i] <- rnorm(n,random.params[i])
}
else{
X[,i] <- sample(c(0,1),n,replace = TRUE,prob=c(random.params[i],1-random.params[i]))
}
}
if(ytype=="continuous"){
Y <- X %*% betas[2:(p+1)] + betas[1] + rnorm(nrow(X),0,200)
} else if(ytype=="binary"){
Z <- X %*% betas[2:(p+1)] + betas[1] + rnorm(nrow(X),0,200)
#pr <- 1/(1+exp(-Z))
pr=exp(Z)/(1+exp(Z))
Y <- rbinom(n,1,pr)
}
df <- data.frame(cbind(X,Y))
names(df)[p+1] <- "y"
# make binary predictors factors
if(include.categorical == TRUE){
df[(p.continuous+1):p] <- lapply(df[(p.continuous+1):p] , factor)
}
return(list(True_Betas=betas,
Data=df))
}
create.regr.data(10,2,ytype = "blood")
devtools::build()
devtools::document()
read.table(http://www.ams.sunysb.edu/~pfkuan/Teaching/AMS597/Data/leukemiaDataSet.txt,
read.table(http://www.ams.sunysb.edu/~pfkuan/Teaching/AMS597/Data/leukemiaDataSet.txt,header=T)
read.table(http://"www.ams.sunysb.edu/~pfkuan/Teaching/AMS597/Data/leukemiaDataSet.txt",header=T)
read.table("http://www.ams.sunysb.edu/~pfkuan/Teaching/AMS597/Data/leukemiaDataSet.txt",header=T)
s <- read.table("http://www.ams.sunysb.edu/~pfkuan/Teaching/AMS597/Data/leukemiaDataSet.txt",header=T)
View(s)
df <- create.regr.data(100,2)
train_test_split(df)
devtools::document()
devtools::load_all()
devtools::install()
df <- create.regr.data(100,2)
train_test_split(df)
